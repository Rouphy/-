# 软件测试大合集

## 一、绪论概论

### 1.1  软件测试流程

1. 在项目版本开始阶段-由产品经理编写出产品需求文档和原型图,召开需求评审会(澄清需求,讨论需求的合理性),需求定稿后将需求文档和原型图给到测试组
2. 根据需求文档和原型图拆分功能,提取测试点,编写思维导图
3. 开测试需求评审会(查看所提取的测试点是否完整,测试人员是否正确理解功能需求)
4. 编写测试计划和测试方案
5. 编写测试用例
6. 测试用例评审(所编写的测试用例是否100%覆盖所有功能点)
7. 搭建测试环境
8. 冒烟测试(测试主功能流程是否可以正常跑通) 
9. 系统集成测试(SIT)/执行测试用例
10. 提交bug(bug管理)
11. 跟踪bug,bug修复完成后,回归测试
12. 编写测试报告,进行软件质量评估
13. 将项目发布至预发布环境(灰度环境)-进行主功能流程测试
14. 发布至生产环境(线上环境)
15. 项目总结,准备下一个版本测试

### 1.2  系统测试（SIT）和验收测试（UAT）有什么区别

##### 目标不同：

UAT的目标是确保软件可以满足用户的需求和预期,确保软件功能已全部实现
SIT的目标是系统中不同模块之间的功能交互是否正常,确保软件功能已满足用户需求
执行者不同：SIT通常由测试人员执行,而UAT通常由最终用户执行

##### 测试内容不同:‌

SIT‌：主要关注功能测试、性能测试、兼容性测试、易用性测试、安全测试、接口测试等。
‌UAT‌：主要关注功能测试、用户界面测试、软件操作文档测试。

##### 测试环境不同：

SIT通常在测试环境中进行,而UAT通常在生产环境中进行

##### 测试时间不同: 

SIT：在单元测试和集成测试之后进行的系统测试
‌UAT‌：在系统测试完成后,软件发布前的验收测试

### 1.3  敏捷开发的优缺点

1. 把一个软件拆分为多个版本,每个版本可对应一部分需求,持续交付有价值的软件给用户使用
2. 后期也支持需求变更
3. 通过敏捷开发快速进行版本迭代更新,每个版本可在7-15天可发布一个新的版本
4. 每一版本都是从需求$\rightarrow$设计$\rightarrow$开发$\rightarrow$测试$\rightarrow$发布组成一个完成的流程
5. 缺点对开发和测试人员技能及业务熟悉程度有一定的要求

### 1.4  缺乏需求文档或需求文档不甚明确的情况下如何展开测试

1. 首先，把需求文档中有异议的部分标识出来，再找产品和开发一起讨论，把需求明确下来；
2. 快速的熟悉系统,提取测试点，然后再叫上产品和开发一起对测试点进行讨论，看有没有遗漏，设计是否合理，然后再编写测试用例，再用例评审，评审通过后，再进行后续的测试。
3. 借鉴或使用同类产品,增加对功能点理解

### 1.5  没有需求文档如何开展测试

1. 与产品经理、开发人员或业务方沟通明确软件需要实现的核心功能，了解功能实现逻辑（如接口依赖、数据流向）
2. 参考软件的历史版本，对比上一版本的功能差异，借鉴同类产品增加对功能点的理解
3. 将收集到的信息细化到思维导图中，进行功能点提取，与产品和开发人员沟通分析功能点是否遗漏或误解
4. 编写测试用例，需要覆盖到正常/异常功能测试，性能测试，易用性测试、安全测试、兼容测试，弱网测试等特性
5. 完成测试用例评审，严格按照测试用例执行

### 1.6  编写测试用例的好处：

1. 防止功能点漏测,避免测试人员盲目测试
2. 缩短测试周期更新版本时只需要更改部分用例,快速进行版本迭代,系统重复测试
3. 便于回归测试,可以利用已有的测试用例进行回归测试,确保没有新的bug引入
4. 提高测试效率,提前准备好测试数据和跟进测试进度,降低与开发交接时间
5. 加快测试人员对软件的理解,减少对测试人员依赖,人员变动也能保证测试工作正常进行

### 1.7  当用户需求变更时你作为测试人员会怎么做

- 重新进行需求分析，补充新增内容的测试点
- 补充测试计划重新安排测试进度，明确新的测试重点和优先级
- 修改和新增测试用例以确保测试覆盖所有变更点
- 执行修改后的测试用例，及时发现并记录新需求引入的缺陷和问题
- 提交bug与跟踪bug，缺陷修复后进行回归测试
- 测试过程中与产品经理、开发人员、项目经理保持密切沟通，及时反馈测试进展，问题和风险，确保项目顺利进行

### 1.8  如何保证在不同的测试环境下的测试结果的一致性

- 环境搭建配置：统一硬件配置、操作系统版本、依赖的相关软件版本及配置全部相同，模拟相同网络环境。
- 数据库数据一致：通过脚本提取准备好测试数据，统一在SVN服务器中获取相同的测试数据
- 测试工具与自动化脚本：选择合适的测试工具版本与配置，使用版本控制系统，如Git/SVN，对测试脚本进行管理，把常用的参数化数据封装在指定的文件中，以便在不同环境下可以灵活替换数据
- 测试流程规范：制定详细、统一的测试流程，要求测试人员严格按照流程进行软件测试，减少盲目测试

### 1.9  你觉得在测试功能中哪个环节最重要

答：测试用例设计

- 测试用例设计是软件测试的首要任务，其主要目的是根据软件的功能和业务需求可预先准备测试方案和测试数据，以便在测试过程中发现潜在的威胁
- 测试用例设计需要覆盖软件的各种功能和场景，同时考虑正常情况和异常情况，确保测试的全面性和有效性，对软件质量提供保障

### 1.10  如何防止功能漏测

- 在项目开始阶段的时候进行需求分析，拆分功能点，编写思维导图，与开发和产品时刻进行沟通，是否存在遗漏拆分不完整
- 设计测试用例场景齐全（符合软件质量特性），完成用例评审
- 搭建与生产环境相近的测试环境，避免环境差异导致覆盖不全，使用真实测试数据（数据库导出）来覆盖不同业务场景
- 严格按照测试用例执行
- 系统测试过程中与其他测试人员进行交叉测试
- 如果已经发生漏测，分析漏测原因及时总结，避免再次漏测

### 1.11  准出原则

- bug修复率（致命100%，严重100%，一般80%-85%，轻微70-75%）
- 至少执行两轮基本测试，一轮回归测试
- 有相关文档产出（产品思维导图，测试计划，测试方案，测试用例，测试报告）
- 测试有效性：符合以上内容，相关责任部门认可测试结果，包括用户的试用，通过验收测试等

### 1.12  测试计划有什么内容

包含测试的目的与范围、角色与职责、资源及安排、风险与应对、测试标准等相关信息；

涉及产品概述、测试策略、测试区域、测试周期、测试资源、测试交流等多个方面

### 1.13  如何制定测试计划

- 根据测试需求文档，明确测试目标和范围
- 安排测试人员和测试资源
- 制定测试用例和项目里程碑
- 规避风险与应对措施
- 规定测试标准与测试环境等相关信息来制定测试计划

### 1.14  测试方案有什么内容

详细描述测试方法、测试环境与测试工具等内容；

包括具体的测试步骤、输入数据、预期结果和实际结果等；

强调测试活动的技术细节和实现方式

### 1.15  测试计划和测试方案有什么区别

测试计划是一个偏管理性质的文档，它详细描述了测试软件的范围、方法、资源、策略、风险和进度，它是软件项目计划的子计划，用于指导整个测试过程，确保测试工作能够有序、有效地进行，是测试工作的总体规划和指导方针

测试计划的主要目的是解决“谁来做”、“做什么”以及“何时做”的问题

测试方案是一个偏技术类型的文档，它详细描述了如何执行测试工作，包括测试方法、测试环境、测试工具，执行功能、性能、安全等等具体的测试步骤，强调测试活动的技术细节和实现方式

测试方案的主要目的是解决“怎么做”的问题，为测试人员提供详细的操作指南

### 1.16  测试过程中什么时候会用到数据库

- 数据准备
  - 比如用户注册成功后、订单被创建后，查询数据库确认数据是否正确存储用户数据，在数据库表中检查对应表中字段是否正确
- 功能验证
  - 当功能出现异常如页面显示数据错误时，通过查询数据库确认
  - 下单后验证订单表、库存表、用户表的数据是否同步更新订单状态为“已支付”时，库存是否扣减，用户余额是否扣除，关联表数据是否一致，如商品表的库存与订单表的扣减数量是否匹配
- 性能测试
  - 向数据库批量造测试数据，如10万条用户记录，测试数据库的写入响应速度
- 缺陷定位
  - 测试SQL注入漏洞：通过接口提交恶意SQL语句，查看数据库是否返回非授权数据或报错 正常应过滤非法字符

### 1.17  测试时间比较紧凑，马上要进行上线，你会怎么合理安排测试工作

1. 与开发团队沟通，明确哪些功能是上线必须支持的核心功能，优先测试这些功能；挑选测试用例优先级较高的执行测试，确保核心功能的稳定性和可靠性
2. 缺陷等级中包含了致命和严重或者影响到用户操作的bug优先进行修复，并回归测试通过
3. 提前准备好自动化脚本，快速执行主功能流程测试和回归测试，减少人工操作，提高测试效率

## 二、缺陷管理

### 2.1  bug中包含哪些内容

- bug的标题
- 所属版本
- 所属模块
- 指派人（开发）
- bug类型
- bug复现步骤
- 实际结果
- 预期结果
- bug截图附件
- 严重程度
- 优先级

### 2.2  定义缺陷的判定标准

- 软件没有实现产品规格说明所要求的功能模块
- 软件中出现了产品规格说明指明不应该出现的错误
- 软件实现了产品规格说明没有提到的功能模块
- 软件没有实现虽然产品规格说明没有明确提及但应该实现的模块
- 软件难以理解，不容易使用，运行缓慢

### 2.3  bug的缺陷等级有哪些，你怎么区别，优先级怎么分配

1. 致命
   - 系统崩溃
   - 功能设计与需求严重不符
   - 系统无法登陆
2. 严重
   - 功能未实现
   - 功能存在报错
   - 数值轻微的计算错误
3. 一般
   - 边界条件下错误
   - 容错性不好
   - 大数据测试容易无响应
   - 大数据操作时，没有提供进度条
4. 轻微
   - 界面颜色搭配不好
   - 文字排列不整齐
   - 出现错别字但不影响正常功能
   - 界面格式不规范

### 2.4  如果你提交了一个bug，但开发人员不认为是bug怎么处理

因为开发与测试看待软件的角度不一致

1. 根据需求文档或原型图，确认是不是bug
2. 确认我们的测试环境和开发环境一致，避免非bug的提交
3. 与开发沟通了解他们认为不是bug的原因，以及向开发表达自己是如何在用户角度判断问题
4. 找到产品经理，测试经理参与判定，全程坚定自身想法，是为了给用户更好的软件使用体验
5. 无论最终是否认定为bug，都需要在缺陷管理中提交，以便后续追溯

### 2.5  如何提交一个高质量的bug

1. 验证bug：

   - 发现bug后，先分析定位一下是不是一个bug，避免非bug的提交

   - 可以通过抓包看看是前端还是后端的问题，检查数据库的数据是否正确，尽量把问题发生的原因或者产生的错误日志找出来，方便开发定位问题

2. 记录并提交bug：

   - 在缺陷管理工具中详细的描述bug的步骤和截图提单给开发，跟踪bug，开发修复完后进行回归测试，确认问题被解决后就关闭这个bug，没有解决并说明情况打回给开发修复

3. 总结bug：

   - 如果出现了严重的bug或者频繁出现的bug，完成修复后及时分析原因，提出改进意见减少此类bug的产生

### 2.6  概率性/偶然性bug怎么处理

1. 首先，详细的记录操作流程和测试数据，按照发现该问题的操作方式和在不同的环境下重复测试，看是否会有该问题；弄清楚bug出现的规律，比如是不是在某个时间段，某个操作步骤下更容易出现
2. 让开发人员在对应的代码模块中添加日志，增加捕获该bug的概率；排查数据库、第三方接口，比如网络延迟、数据返回慢导致异常产生；如果问题复现成功，及时回归测试确保没有新的bug引入，修复后上线需多次重复测试确保问题被完全修复
3. 如果当前版本无法重现就让bug进行挂起，后续的版本中再次测试发现就重新激活bug，多个版本中没有再发现则关闭

### 2.7  线上出现了bug如何处理

1. 先了解用户反馈的问题和复现的步骤，确认是不是一个bug
2. 确认是问题后进行复现bug（确认用户软硬件环境，尽可能与用户环境保持一致复现bug的概率会更高）
3. 确认bug严重程度，严重和影响用户使用的问题立马修改，修复后，先在测试环境确保问题已经解决，没有引发新的问题，进行全面更新，跟踪问题上线直到被彻底解决

### 2.8  你们的项目大概多久迭代一次，每次迭代会发现多少个bug

一般1-2周会进行一次小版本迭代，一个月会进行一次大版本迭代

小版本迭代一般都是做一些UI界面的优化和bug的修复，产生新的bug数量会少一点，大概在20-30个左右

大版本迭代就会有加入刚研发的新功能，产生的bug数量上百个是有的

### 2.9  说一个印象最深刻的bug（最少3个）

- 我在测试项目的过程中，打开app时会有开屏广告，这个广告有可能是单独一个也有可能是多个视频片段拼接而成。在播放广告时，可能会存在某个广告没有播放，展示白屏，当时我以为是前端bug，播放器没有播放或者没有渲染，通过抓接口发现后端返回的是null，通过查服务器日志发现是后端没有取到值，返回的是一个null，通过查看数据库发现之前上传的数据（广告）不存在，确定是上传接口那边的bug导致白屏
- 我之前在测试电商系统时，新增入库单号是通过前端以当前时间段自动生成的，且是必填项，通过页面创建入库单时是没有问题的。但在api测试时，我绕过前端页面必填的限制给入库单号传入null值时发现也能正常创建入库单，但是页面展示的入库单号为空，影响后面的查询入库单和出库等流程，bug的原因是后端没有对这个入库单做必填校验
- 我记得好像有这样一个bug，一般列表翻页功能都比较简单很少出现问题，但我们当时就发现了这样一个问题，就是每次从首页点击下一页后，显示的依然还是第一页的内容，后来发现每次点击按钮页面都会快速的刷新两次，经过和开发一起抓包定位发现出现bug的原因是在点击下一页的时候又触发了页面的查询功能，默认又显示首页了

### 2.10  bug的生命周期

- 发现bug
- 提交bug
- 指派bug
- 分析和确认bug
- 处理并修复bug
- 回归验证bug
- 关闭bug
- 挂起bug

### 2.11  测试报告中包含哪些内容

- 项目简介和目的
- 测试参考文档
- 测试用例设计方法
- 测试方法
- 测试用例执行情况
- 系统测试总结及风险规避措施

| 风险                                         | 措施                                                         |
| -------------------------------------------- | ------------------------------------------------------------ |
| 测试时间短暂导致测试用例覆盖不全面           | 申请更多测试时间，提前准备自动化脚本缩短测试时间，提高测试效率 |
| 功能点漏测                                   | 需求评审和用例评审，测试人员严格按照测试用例执行，进行交叉测试 |
| 未召开用例评审会导致测试用例覆盖不全面       | 召开测试用例评审会                                           |
| 原型图难以理解，未开需求评审会导致需求不明确 | 召开需求评审会                                               |
| 各部门对接缓慢                               | 规划里程碑                                                   |
| bug修复不及时导致上线延期                    | 咨询开发里程碑，规划好时间                                   |

## 三、接口API自动化理论

### 3.1  接口测试流程

1. 由开发提供接口测试文档
2. 根据接口测试文档提取测试点
3. 编写接口测试用例
   - 设计正常异常测试用例，正常验证接口逻辑是否正确，根据接口业务逻辑、输入参数，查看响应数据是否与预期结果一致
   - 异常用例，不按照接口文档上的要求输入参数，来验证接口对异常情况的校验（参数的类型、参数的长度、参数是否必传、是否加密、关联数据的获取）
4. 接口测试用例评审
5. 搭建接口测试环境
6. 构建接口请求，执行接口测试用例，引入参数化、断言、连接数据库进行垃圾数据回收、异常处理等
7. 提交bug，跟踪bug，进行回归测试，bug修复后
8. 编写接口测试报告，评估接口测试结果，准备功能测试

### 3.2  Fiddler的工作原理

Fiddler其实就是客户端和服务器之间起到了一个代理的作用，它可以监听客户端和服务器的HTTP通信，抓取拦截网页HTTP及HTTPS请求与响应数据，篡改请求和响应报文，进行弱网测试等

### 3.3  Fiddler常用功能

- 当测试出现bug时，可以通过Fiddler抓取拦截网页HTTP及HTTPS请求与响应数据进行分析是客户端问题还是服务端问题
- 可进行简单接口测试，通过抓包获取接口的入参和返回值
- 篡改请求和响应数据，测试对应的逻辑处理能力
- 弱网测试，模拟出不同的网络速度
- 设置拦截规则，抓取指定的接口请求
- 远程连接抓取app请求响应数据

### 3.4  一个接口请求不通（或者网页无法访问），该如何排除问题

1. 先排除自身操作问题，ip或者端口号或者url写错了
2. 客户端和服务端网络不通
3. 服务端项目根本没有部署起来
4. 服务器的防火墙拦截了
5. 服务端程序内部发生了错误
6. 没有访问权限（比如缺乏token、cookie之类）
7. 客户端设置了网络代理，如果是浏览器访问，是不是绑定了错误的主机地址

### 3.5  接口测试要关注哪些内容

- 接口的业务功能是否实现
- 发送给服务器的正常异常请求参数，服务器响应给客户端的信息是否和预期结果一致
- 接口在传输敏感数据是否加密处理，接口是否正确验证用户身份授权和防止未授权的访问
- 接口在不同负载条件下的响应时间是否符合需求

#### ——接口测试我们还会关注

- 是否满足前提条件，有些接口需要满足前提，才可成功获取数据。常见的需要登录Token
- 是否携带默认值参数
- 正常用例：带默认值的参数都不填写、不传参，必填参数都填写正确且存在的常规值，其他不填写
- 结合业务规则、功能需求，接口参数说明，设计正常用例和异常用例
- 参数是否必填
- 参数之间是否存在关联
- 参数数据类型限制
- 参数数据类型自身的数据范围值限制
- 返回结果校验，数据库校验结果是否符合
- 接口安全验证（绕过身份验证，参数是否加密）

### 3.6  为什么要做接口测试及好处

1. 尽早介入测试，降低修复成本，接口测试可以检查UI界面无法发现的问题，绕过前端验证，测试后端
2. 接口测试深入到系统内部，直接对各模块之间的接口进行测试，接口测试完成，后端不变，前端任意变动
3. 接口测试可以通过自动化快速执行大量测试用例，提高测试效率
4. 测试接口可以在短时间内覆盖更多测试场景，一定比功能测试更快
5. 让测试人员更熟悉业务功能实现逻辑

### 3.7  如何判断一个bug是属于前端还是后端

- 根据经验来看，如果这个bug是界面排版布局，兼容性或者CSS/JS未加载完全或者请求超时都是属于前端bug
- 对于数据或者逻辑处理上的问题，我们则可以通过浏览器开发者工具、Fiddler工具进行抓包查看日志分析：
  - 对着接口文档，看请求参数的正确性，有问题就是前端发的数据问题，则为前端bug
  - 查看接口响应报文，响应的数据内容不正确，那就是后端处理出错导致的bug
- 还可以查看相关服务器报错日志，分析日志中的异常报错信息，查看数据库中的数据来判断前端还是后端问题

### 3.8  测试过程中、发现系统在特定环境下频繁出现数据错误，你会怎么一步步排查问题

1. 确认问题现象

   收集错误信息：详细记录系统报错信息，包括错误提示内容、出现错误的具体操作步骤等

   复现问题：尝试在相同环境下，按照用户提供的操作步骤再次执行，确认问题是否稳定复现，若能复现，可更好地进行后续排查；若不能，查看是否存在操作遗漏或环境未完全一致等情况再重复测试

2. 检查测试环境

   查看服务器硬件状态，如CPU使用率、内存占用、磁盘空间等是否存在异常

   高CPU使用率或内存不足可能导致系统处理数据出错；磁盘空间不足可能影响数据读写

3. 抓包分析数据流向

   查看请求数据：检查输入数据的格式、类型、取值范围是否符合系统要求

   例如，是否存在本应输入数据却输入了字符的情况；数据是否存在缺失值、异常值等

   查看响应数据：检查输入数据的展示或存储是否正确，如是否存在数据丢失、格式错误等问题，对比输出数据与原始输入数据及预期结果的差异

4. 与小组沟通排查

   与开发沟通：将问题现象、排查过程告知开发人员，共同分析代码逻辑和可能存在的问题，同时检查服务器配置、网络环境等，确保环境稳定且符合系统运行要求

### 3.9  加密接口如何测试

首先要搞到接口的加密方式：

- 对称加密

  从开发那里获取到对称加密的密钥，获取到解密报文

- 非对称加密

  从开发那里获取到加密过程中有两个密钥，分别为公钥（public key）和私钥（private key）

  如果使用公钥对数据进行加密，只有用对应的私钥才能进行解密，获取到解密报文

  如果使用私钥对数据进行加密，只有对对应的公钥才能进行解密，获取到解密报文

### 3.10  常见的加密算法

- DES加密算法（Data Encryption Standard），对称加密
- AES加密算法（Advanced Encryption Standard），对称加密
- RSA加密算法（非对称加密算法）
- Base64加密算法
- MD5加密算法（非对称）

### 3.11  接口自动化的数据如何重复使用

每次做完自动化测试之后，都要对自动化测试环境进行恢复，意思就是，在执行自动化测试时增加的数据要删除（数据回收），修改的数据要恢复到原来的样子

可以有两种方法：

- 在测试之前，先备份数据库，测试完成之后，用备份的数据库数据覆盖现在环境上的数据
- 在自动化脚本中，增加删除或者修改的步骤，把测试环境恢复到测试前的状态

### 3.12  项目所有的接口都会去编写接口自动化脚本吗？接口自动化覆盖率是多少？

我们主要针对项目的主功能流程编写接口自动化，包括正常和异常场景及关联性接口都会设计测试用例来提高覆盖率，接口自动化覆盖率会达到70%以上

#### ——为什么覆盖率是70%而不是100%呢？

因为对于接口测试覆盖率取决于项目的需求和接口复杂程度，在测试接口项目过程中可能会存在一些难以构造的数据或者逻辑性较强的接口

如果遇到这种情况，接口测试覆盖率不必强求达到100%的覆盖率，但是接口测试一定要覆盖到主要场景和回归主流程，多考虑异常场景和异常参数的构造来增加接口覆盖率

### 3.13  你们接口自动化测试用例通过率是多少？

如果没有什么异常情况，自动化脚本都是100%运行通过；

如果异常情况比较多，比如出现测试环境不稳定，或者开发修改了代码没通知到测试人员及时修改脚本，又或者开发引入了新的问题等等，自动化脚本通过率就可能会低一些

### 3.14  你觉得你们做这个自动化的好处在哪里

1. 提高回归测试的效率。自动化测试，可以不断地执行之前执行过的用例，减轻人力成本
2. 由于每次自动化测试运行的脚本是相同的，所以每次执行的测试具有一致性，减少人为的失误
3. 自动化测试，可以安排晚上的时间进行，更好的利用资源

### 3.15  你们这个项目你一共写了多少条接口测试用例

我所负责的项目模块有登录，加入购物车，订单确认，订单结算，及后台商品管理，分类，订单管理，用户管理等功能

第一个版本迭代产出测试用例在1000-1500左右，因为在测试过程中有时候也会遇到需求变更和功能调整，为了提高测试用例质量和覆盖率也会不断追加测试用例，一直到最近的项目版本大概有3500多条测试用例

### 3.16  风险评估案例分析

如果你负责一款即将上线的医疗产品的功能测试，列举并解释可能存在的三大测试风险，并提出相应的预防或解决措施

1. 需求变更风险：医疗产品在开发过程中需求可能发生变化，导致已完成的测试用例失效或需要重新测试

   解决措施：建立严格的需求变更管理流程，对需求变更进行评估和影响分析；及时更新测试计划和测试用例，确保与最新需求一致

2. 时间紧迫风险：项目上线时间固定，测试时间可能被压缩，导致测试不充分

   解决措施：提前与项目团队沟通，合理安排测试时间；采用风险驱动的测试策略，优先测试高风险功能模块；必要时可申请增加测试资源或调整上线计划

3. 测试环境不一致风险：开发、测试、生产环境可能存在差异，导致在测试环境正常的功能在生产环境出现问题

   解决措施：尽量保证各环境的一致性，包括操作系统、数据库版本、中间件配置等；在测试后期进行生产环境预演测试，模拟生产环境进行测试，提前发现并解决环境差异问题

### 3.17  在一次项目部署后，用户反馈系统间歇性出现500Internal Server Error错误，作为测试人员列出你将采取的故障排查步骤

1. 收集信息：向用户了解错误出现的具体场景，如操作步骤、出现频率、是否有特定时间规律等；查看服务器日志，获取错误发生时的详细日志信息，包括错误堆栈、时间戳等
2. 分析日志：根据日志中的错误堆栈信息，定位可能出错的代码模块或函数，判断是应用程序代码问题、数据库问题还是中间件问题
3. 复现问题：在测试环境中按照用户描述的操作步骤尝试复现问题，如果能复现，进一步缩小问题范围，进行调试分析；若无法复现，考虑是否是生产环境特有的问题，如资源限制、配置差异等
4. 排查配置：检查服务器的配置参数，如内存、CPU使用情况、数据库连接配置、中间件配置等，看是否存在配置不合理或资源不足导致错误
5. 代码检查：针对可能出错的代码模块，进行代码审查，检查是否存在逻辑错误、空指针异常、数据库事务问题等
6. 逐步修复验证：根据排查结果进行修复，修复后在测试环境验证问题是否解决，然后在生产环境进行灰度发布验证，确认问题彻底解决

## 四、接口自动化与CI/CD（JMeter+Ant+Jenkins）

### 4.1  Ant是什么工具

Ant是一个功能强大的打包编译工具，我们可以使用它里面的build.xml帮我们自动运行JMeter脚本并将聚合报告JTL（xml）格式编译成html格式的测试报告

### 4.2  Jenkins是什么工具，你用它完成了什么操作

Jenkins是一个开源的持续集成和持续部署（CI/CD）工具

我们使用它跟Ant完成了定时自动构建JMeter脚本，并自动生成一个HTML报告

### 4.3  Jenkins周期构建的日程表中五颗星代表什么

分	时	日	月	周

```
MINUTE HOUR DOM MONTH DOW
```

| tag    | meaning                                             |
| ------ | --------------------------------------------------- |
| MINUTE | Minutes within the hour (0–59)                      |
| HOUR   | The hour of the day (0–23)                          |
| DOM    | The day of the month (1–31)                         |
| MONTH  | The month (1–12)                                    |
| DOW    | The day of the week (0–7) where 0 and 7 are Sunday. |

### 4.4  接口测试流程/JMeter接口自动化流程

1. 拿到接口文档熟悉

   - 每个接口对应要实现的功能是什么
   - 服务器的地址、端口、接口地址
   - 请求方式，请求参数有哪些，参数的约束条件是什么，加密方式是什么（工作当中了解请求参数的各种约束条件
   - 熟悉响应数据
     - 响应的字段有哪些
     - 正确和错误的响应码有哪些，对应的响应信息是什么

2. 编写接口测试用例（接口测试用例跟功能类似，只多了一个请求报文，响应报文）

   1. 设计正常异常测试用例，正常验证接口逻辑是否正确，根据接口业务逻辑、输入参数，查看响应数据是否和预期结果一致
   2. 异常用例，不按照接口文档上的要求输入参数，来验证接口对异常情况的校验（参数的类型、参数的长度、参数是否必传、是否加密、关联数据的获取）

3. 接口测试用例评审、执行测试用例

   先建立一个线程组，再添加http请求，填写好请求地址，端口和请求参数，设置参数化，添加断言等，如果有依赖数据进行提取后，在添加查看结果树再运行

   运行完后，检查接口是否通过，如果不通过，先定位下原因，如果是请求的参数有问题，修改后再进行测试，如果是接口本身存在bug，就把服务器上的日志取下来，提单给开发修改，进行回归测试；等到接口bug修复后，就可以放到搭建好的Ant+JMeter+Jenkins框架上做持续集成测试

4. 最后自动生成接口测试报告，评估接口测试结果，准备功能测试

### 4.5  JMeter中怎么完成数据回收

1. 在测试计划中添加mysql连接jar包
2. 线程组中添加配置插件-JDBC Connection Configuration
3. 在需要完成数据回收的接口后添加一个JDBC Request，编写sql删除语句并提取到需要被回收的数据
4. 比如说我们接口回收的是订单创建后的orderId，我会在订单创建接口添加一个后置处理器提取到orderId并在JDBC Request中的删除语句中进行调用来实现删除，删除后可以调用订单列表的接口来查看这个订单是否被删除成功

### 4.6  断言（assert）的作用

主要在开发或者测试阶段发现和验证代码中的逻辑结果，当设置的断言结果不满足的时候，程序会直接抛出异常，让开发或者测试人员可以快速的查看到响应结果并进行调试，添加断言后就不必等待程序运行后才出现异常的情况

### 4.7  常见的断言方式

`a==b`	`a!=b`	`a in b`	`a not in b`



## 五、Postman/Apipost

### 5.1  postman怎么构建一个post请求的接口

创建一个http请求，填写好请求地址，在body中添加请求参数，后执行操作中添加断言等，发送请求，查验结果（断言）是否通过

### 5.2  postman怎么提取关联数据

1. 对应接口中在后执行操作中添加响应数据编写提取代码，将提取到的关联数据添加至默认环境中
2. 在需要引用的接口中使用`{{变量名称}}`进行调用

### 5.3  postman怎么添加响应断言

后执行操作中添加断言，提取响应数据中的msg内容，编写断言包含内容

### 5.4  postman怎么去构建一个get请求的接口

创建一个http请求，填写好请求地址端口，在Query中添加请求参数，后执行操作中添加断言等，发送请求，查验结果（断言）是否通过

### 5.5  postman怎么实现数据驱动

1. 创建一个csv文件，添加测试数据
2. 在自动化测试中（Collection Runner）新建测试数据，导入csv文件，保存文件后登录接口中通过`{{变量名称}}`进行调用
3. 在自动化测试中进行引用测试数据，调整执行次数，保存并运行后查看运行结果

### 5.6  Apipost中的运行环境和Mock环境区别

#### 运行环境

- 数据来源：直接与真实的后端服务器交互，使用真实的接口数据
- 使用场景：用于接口的实际测试、调试，确保接口在真实环境下的功能正确性和稳定性

#### Mock环境

- 数据来源：通过预先设置好的 Mock规则生成模拟数据，不依赖真实的后端服务
- 使用场景：当后端服务尚未开发完成时，前端可以利用Mock环境进行接口测试和开发，提前构建页面逻辑和交互效果

### 5.7  在完成接口测试时依赖于第三方接口的数据怎么操作

1. postman中可以使用Mock服务模拟第三方返回正常/异常场景
2. 在测试环境中配置第三方服务的地址和端口来完成测试，比如手机号验证码登录接口在JMeter中去构建接口发送请求，输入测试手机号码获取验证码，再将提取到的验证码给需要关联的接口，观察返回结果是否符合预期
3. 如果有多个接口都存在依赖关系，可以使用自动化方式让接口按照顺序批量执行，保证数据传递和依赖关系的正确性

### 5.8  测试过程中，发现系统在特定环境下频繁出现数据错误，你会怎么一步步排查问题

1. 确认问题现象

   收集错误信息：详细记录系统报错信息，包括错误提示内容，出现错误的距离操作步骤等

   复现问题：尝试在相同环境下，按照用户提供的操作步骤再次执行，确认问题是否稳定复现

   若能复现，可更好地进行后续排查；若不能，查看是否存在操作遗漏或环境未完全一致等情况再重复测试

2. 检查测试环境

   查看服务器硬件状态，如CPU使用率、内存占用、磁盘空间等是否存在异常

   高CPU使用率或内存不足可能导致系统处理数据出错；磁盘空间不足可能影响数据读写

3. 抓包分析数据流向

   查看请求数据：检查输入数据的格式、类型、取值范围是否符合系统要求

   例如，是否存在本应输入数值却输入了字符的情况；数据是否存在缺失值、异常值等

   查看响应数据：检查输出数据的展示或存储是否正确，如是否存在数据丢失，格式错误等问题，对比输出数据与原始输入数据及预期结果的差异

4. 与小组沟通排查

   与开发沟通：将问题现象、排查过程告知开发人员，共同分析代码逻辑和可能存在的问题，同时检查服务器配置、网络环境等，确保环境稳定且符合系统运行要求

### 5.9  深圳龙岗地区某用户使用公司的“H”小程序界面显示不正常，请各位测试精英排查问题，可能有哪些原因造成

1. 复现问题：

   使用与用户相同型号的手机，安装相同版本的操作系统，尽量模拟到与用户相同的网络环境；打开小程序，观察界面显示情况，查看是否能发现与用户描述的问题一致；界面显示不正常表明问题可能与该手机型号、操作系统版本或特定网络环境有关

2. 排查网络因素：

   进行弱网测试切换网络连接，从WiFi切换到移动数据（3G,4G,5G），或从移动数据切换到不同的WiFi网络，再次打开小程序进行测试

   是否存在加载速度较慢，存在延迟和丢包现象

   检查用户手机的网络设置，查看是否存在代理服务器设置，VPN连接或其他可能影响网络访问的设置，关闭该代理设置后，重新打开小程序，界面显示是否恢复正常

3. 检查设备兼容性：

   在多种不同手机型号和系统版本及不同分辨率的移动设备上测试小程序，查看是否存在设备兼容性问题

### 5.10  第三方支付接口需要对接哪些内容

对接支付宝接口时，需根据具体业务需求（如支付、退款、查询等）准备相关要素，核心对接内容可分为以下几类：

1. 前期准备

   开发者账号：注册并认证支付宝开放平台账号（open.alipay.com），创建应用（区分沙箱环境和生产环境）

   资质材料：企业用户需提供营业执照、法人信息等，个体工商户需对应资质，用于应用审核

   密钥配置：生成RSA或SM2密钥，在开放平台配置应用公钥，获取支付宝公钥，用于接口加解密和签名验证

2. 核心接口类型

   - 支付类接口

     电脑网站支付、手机网站支付、APP支付、小程序支付等，对应接口如`alipay.trade.page.pay`（电脑支付）、`alipay.trade.app.pay`（APP支付）。需处理支付参数（商户订单号、金额、标题等）、签名及回调通知

   - 订单管理接口

     支付查询、退款、退款查询等，用于核实订单状态或处理售后

   - 回调通知接口

     支付结果异步通知（需在开放平台配置回调地址），用于接收支付宝异步推送的支付结果，需验证签名确保信息真实性

   - 其他辅助接口

     如获取用户信息（需用户授权，对应`alipay.user.info.share`接口），账单下载等，根据业务需求选择

3. 技术对接要点

   SDK集成：支付宝提供多种语言SDK（Java、Python、PHP等），简化签名、参数处理等流程

   环境区分：先通过沙箱环境（提供测试账号、密钥）调试，再切换到生产环境

   签名验证：所有接口请求和回调通知均需通过密钥签名，确保数据安全，避免篡改

   异常处理：处理网络超时、支付中断等情况，通过查询接口确认最终状态